{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LLM for Hotel Customer care"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotel HuTao offers an online service where customers can interact with customer care representatives to resolve their doubts and queries. Maintaining a 24/7 live chat-based service with human representatives is costly and resource-intensive. To address this, we will train a large language model (LLM) using previously collected conversations to handle customer queries more efficiently.\n",
    "\n",
    "In this notebook, we will utilize the dataset `Octopussss/HuTao_CustomerSupport_Hotel` from Hugging Face. This dataset contains historical conversations between customers and Hotel HuTao's customer care representatives, which will be used to train our model.\n",
    "\n",
    "Let's begin by exploring the dataset and preparing it for training.\n",
    "\n",
    "Sample dataset format:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"query\": #query,\n",
    "        \"response\": #response,\n",
    "    },\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Is parking available at the hotel?',\n",
      " 'response': 'Yoh, now why might you be looking for parking, hm? Oh, you '\n",
      "             \"didn't know? Well, let me tell you, parking at the Continental \"\n",
      "             \"Hotel is as smooth as a summer breeze! We've got a lovely \"\n",
      "             'parking lot right out front, with plenty of spots for our '\n",
      "             \"esteemed guests. And don't worry, it's all well-lit and secure, \"\n",
      "             'so you can rest easy knowing your vehicle is safe and sound. '\n",
      "             'Now, would you like me to give you directions to the parking '\n",
      "             'lot?'}\n"
     ]
    }
   ],
   "source": [
    "# prepare seed examples in required format\n",
    "import json\n",
    "import datasets\n",
    "from pprint import pprint\n",
    "\n",
    "data = datasets.load_dataset(\"Octopussss/HuTao_CustomerSupport_Hotel\")\n",
    "n_seed_samples = 10\n",
    "data = [\n",
    "    dict(query=d['Questions'], response=d['Response']) \n",
    "        for d in data['train'].to_list()[0:n_seed_samples]\n",
    "]\n",
    "json.dump(data, open('hotel_seed_data.json', 'w'))\n",
    "pprint(data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a client class with your own Leeroo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: leeroo-mistral Logged in!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from leeroo_client.client import LeerooClient\n",
    "\n",
    "leeroo_api_key = \"your-api-key-here\"\n",
    "client = LeerooClient(\n",
    "    leeroo_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For designing the experiments, you need to provide us:\n",
    "\n",
    "- `evaluation_description` (optional): A short summary of your application, and what are important evaluation factors in your mind. Just describe them in natural language.  \n",
    "- `workflow_name` : The name of this experiment. This will be later saved along with the id of workflow.  \n",
    "- `seed_data_path` (optional): Your dataset for the desired application. The dataset should follow JSON format with `query` and `response` as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_policy = \\\n",
    "\"\"\"\n",
    "    Evaluation Policy for Customer Care Responses\n",
    "    - Responses should capture the user's attention and encourage further interaction.\n",
    "    - Aim for a friendly and approachable tone to foster a positive customer experience.\n",
    "    - Avoid jargon and overly technical language unless necessary for the context.\n",
    "    - Incorporate light-hearted humor where appropriate to create a pleasant interaction, while ensuring it remains suitable for all audiences.\n",
    "    - Humor should enhance the conversation without detracting from the core message.\n",
    "    - Personalize responses when possible to show genuine care for the customerâ€™s needs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_gen_config': {'task_description': \"\\n    Evaluation Policy for Customer Care Responses\\n    - Responses should capture the user's attention and encourage further interaction.\\n    - Aim for a friendly and approachable tone to foster a positive customer experience.\\n    - Avoid jargon and overly technical language unless necessary for the context.\\n    - Incorporate light-hearted humor where appropriate to create a pleasant interaction, while ensuring it remains suitable for all audiences.\\n    - Humor should enhance the conversation without detracting from the core message.\\n    - Personalize responses when possible to show genuine care for the customerâ€™s needs.\\n\",\n",
       "  'no_samples': 5,\n",
       "  'seed_path': 'dager/backend/uploads/hotel_seed_data.json'},\n",
       " 'experiment_config': {'0': {'model_args': {'model_id': 'mistralai/Mistral-7B-v0.1',\n",
       "    'quantized': True},\n",
       "   'training_methods_args': {'r': 32,\n",
       "    'lora_alpha': 32,\n",
       "    'lora_dropout': 0.05,\n",
       "    'target_modules': ['q_proj', 'k_proj', 'v_proj']},\n",
       "   'training_args': {'fp16': True,\n",
       "    'num_train_epochs': 2,\n",
       "    'learning_rate': 0.0001,\n",
       "    'lr_scheduler_type': 'linear',\n",
       "    'warmup_ratio': 0.1}}},\n",
       " 'user_config': {'user_id': 'leeroo-mistral',\n",
       "  'workflow_name': 'TheChatGiggle',\n",
       "  'task_description': \"\\n    Evaluation Policy for Customer Care Responses\\n    - Responses should capture the user's attention and encourage further interaction.\\n    - Aim for a friendly and approachable tone to foster a positive customer experience.\\n    - Avoid jargon and overly technical language unless necessary for the context.\\n    - Incorporate light-hearted humor where appropriate to create a pleasant interaction, while ensuring it remains suitable for all audiences.\\n    - Humor should enhance the conversation without detracting from the core message.\\n    - Personalize responses when possible to show genuine care for the customerâ€™s needs.\\n\",\n",
       "  'budget': 2.0,\n",
       "  'seed_path': 'dager/backend/uploads/hotel_seed_data.json',\n",
       "  'session_id': 1721076128.177195,\n",
       "  'eval_config_path': 'eval_config.json'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_configs = client.initialize_workflow_configs(\n",
    "    evaluation_description= evaluation_policy,\n",
    "    workflow_name=\"TheChatGiggle\",\n",
    "    seed_data_path=\"hotel_seed_data.json\",\n",
    "    budget=2 # days\n",
    ") \n",
    "workflow_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ Once you're happy with hyper-parameters, you can submit the training workflow. It will **automatically execute experiments, evaluate them, and pick the best model** based your customized evaluation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      " Workflow running state: {'workflow_runnning_state_id': '1721076129'}\n"
     ]
    }
   ],
   "source": [
    "# Submit workflow for execution\n",
    "running_workflow_status = client.submit_workflow(\n",
    "    workflow_configs=workflow_configs\n",
    ")\n",
    "print(\" Workflow running state:\", running_workflow_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the status of all your workflows, by running the following command:\n",
    "\n",
    "- `runing_workflows`: shows the training workflows with `running` status.  \n",
    "- `finished_workflows`: shows executed workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Total finished workflows : 4\n",
      "Total running workflows : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user_id': 'leeroo-mistral',\n",
       "  'workflow_runnning_state_id': '1721076129',\n",
       "  'workflow_name': 'TheChatGiggle',\n",
       "  'workflow_start_timestamp': 1721076129.664791,\n",
       "  'status': 'running'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve user's workflows\n",
    "user_workflows = client.all_workflows()\n",
    "\n",
    "print( f\"Total finished workflows : {len(user_workflows['finished_workflows'])}\")\n",
    "print( f\"Total running workflows : {len(user_workflows['running_workflows'])}\")\n",
    "\n",
    "user_workflows['running_workflows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further details on the status of a specific workflow, you can run the following function:\n",
    "\n",
    "- `status`: overal status of workflow\n",
    "- `workflow_node_status`: status of all nodes\n",
    "- `workflow_name`: name of your workflow\n",
    "- `workflow_running_state_id`: id of your workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_id': 'leeroo-mistral',\n",
       " 'workflow_runnning_state_id': '1721076129',\n",
       " 'workflow_name': 'TheChatGiggle',\n",
       " 'workflow_start_timestamp': 1721076129.664791,\n",
       " 'status': True,\n",
       " 'workflow_node_status': {'DataGenConfig-172107612957887knqr': 'Executed',\n",
       "  'DataPrepConfig-172107612957891nkbk': 'Executed',\n",
       "  'SFTrainingConfig-172107612957902iqis': 'Executed',\n",
       "  'EvalResponseGenConfig-172107612957904hhle': 'Executed',\n",
       "  'EvalConfig-172107612957912ljmi': 'Executed',\n",
       "  'PickBestConfig-172107612957893eeim': 'Executed'},\n",
       " 'workflow_completed_timestamp': 1721079157.899672}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check status of the running workflow\n",
    "workflow_status = client.get_workflow_status('1721076129')\n",
    "workflow_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'cluster_name': 'DeploymentState-1721079764.328797', 'status': 'Deployment started'}\n"
     ]
    }
   ],
   "source": [
    "# Deploy the workflow\n",
    "workflow_id = '1721076129'\n",
    "deployment_status = client.deploy_workflow(\n",
    "    workflow_id\n",
    ")\n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'DeploymentState-1721079764.328797',\n",
       " 'ip': '54.227.170.247',\n",
       " 'gradio-playground': 'http://54.227.170.247:8000',\n",
       " 'api-access': 'http://54.227.170.247:9000',\n",
       " 'status': 'Deployed'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_workflow_deployment_status('DeploymentState-1721079764.328797')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint.hf'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Model id\n",
    "import requests\n",
    "model_id = requests.get( \"http://54.227.170.247:9000/v1/models\").json()['data'][0]['id']\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'Yes, we offer parking at our hotel. However, we recommend that you check with the management regarding'}\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "url = \"http://54.227.170.247:9000/v1/chat/completions\"\n",
    "data = {\n",
    "    \"model\": model_id,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Is parking available at the hotel?\"}],\n",
    "    \"max_tokens\": 20,\n",
    "    \"temperature\": 0.9\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json()['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'DeploymentState-1721079764.328797',\n",
       " 'status': 'Deployment Killed'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.kill_deployment(\n",
    "    'DeploymentState-1721079764.328797'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2_p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
