{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetunning LLM : Text to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating SQL queries from natural language descriptions can significantly streamline data retrieval and improve efficiency. This task involves training a model to interpret text descriptions and convert them into accurate SQL queries that can be executed against a database to fetch the desired information.\n",
    "\n",
    "In this notebook, we will utilize a dataset `gretelai/synthetic_text_to_sql` containing pairs of natural language descriptions and corresponding SQL queries. The dataset will be used to train our model. Additionally, we will provide the model with SQL context to ensure accurate and context-aware query generation.\n",
    "\n",
    "Let's begin by exploring the dataset and preparing it for training.\n",
    "\n",
    "Sample dataset format:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"query\": #query,\n",
    "        \"response\": #response,\n",
    "    },\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 999/100000 [00:00<00:10, 9256.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'query': '## sql context :\\n'\n",
      "          'CREATE TABLE ClientInvestments (ClientID INT, InvestmentType '\n",
      "          'VARCHAR(20), Value FLOAT); INSERT INTO ClientInvestments (ClientID, '\n",
      "          \"InvestmentType, Value) VALUES (1, 'Stock', 10000), (1, 'Bond', \"\n",
      "          \"20000), (2, 'Stock', 30000), (2, 'Bond', 15000), (3, 'Stock', \"\n",
      "          \"5000), (3, 'Bond', 25000), (4, 'Stock', 40000), (4, 'Bond', 30000), \"\n",
      "          \"(5, 'Stock', 7000), (5, 'Bond', 18000); CREATE TABLE Clients \"\n",
      "          '(ClientID INT, State VARCHAR(20)); INSERT INTO Clients (ClientID, '\n",
      "          \"State) VALUES (1, 'NY'), (2, 'TX'), (3, 'CA'), (4, 'NY'), (5, \"\n",
      "          \"'TX');\\n\"\n",
      "          '\\n'\n",
      "          '## Query generation task:\\n'\n",
      "          'What is the total value of investments in bonds for clients '\n",
      "          'residing in Texas?\\n'\n",
      "          '\\n',\n",
      " 'response': 'SELECT SUM(Value) FROM ClientInvestments CI JOIN Clients C ON '\n",
      "             \"CI.ClientID = C.ClientID WHERE C.State = 'TX' AND InvestmentType \"\n",
      "             \"= 'Bond';\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare seed examples in required format\n",
    "import json\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "dataset = datasets.load_dataset(\"gretelai/synthetic_text_to_sql\")\n",
    "n_seed_samples = 1000\n",
    "data = []\n",
    "\n",
    "for d in tqdm(dataset['train']):\n",
    "    data.append(\n",
    "        dict(\n",
    "            query = f\"## sql context :\\n{d['sql_context']}\\n\\n## Query generation task:\\n{d['sql_prompt']}\\n\\n\",\n",
    "            response = d['sql']\n",
    "        )\n",
    "    )\n",
    "    if len(data) == n_seed_samples:\n",
    "        break\n",
    "\n",
    "json.dump(data, open('texttosql_seed_data.json', 'w'))\n",
    "print(len(data))\n",
    "pprint(data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a client class with your own Leeroo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: arshad Logged in!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dager.clients.client import LeerooClient\n",
    "\n",
    "\n",
    "leeroo_api_key = \"<api-key-here>\"\n",
    "client = LeerooClient(\n",
    "    leeroo_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For designing the experiments, you need to provide us:\n",
    "\n",
    "- `evaluation_description` (optional): A short summary of your application, and what are important evaluation factors in your mind. Just describe them in natural language.  \n",
    "- `workflow_name` : The name of this experiment. This will be later saved along with the id of workflow.  \n",
    "- `seed_data_path` (optional): Your dataset for the desired application. The dataset should follow JSON format with `query` and `response` as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_policy = \\\n",
    "\"\"\"\n",
    "Extract SQL Context:\n",
    "Review the SQL context given in the input, including table definitions and any sample data inserted into these tables.\n",
    "\n",
    "Formulate Expected Query:\n",
    "Based on the task description, determine the logical structure and components of the SQL query that should be generated. For instance, identify the relevant tables, columns, and conditions that should be included in the query.\n",
    "\n",
    "Check Query Components:\n",
    "Ensure the generated query includes the correct tables and columns specified in the SQL context.\n",
    "Verify that the conditions and clauses in the query match the task description. For example, checking for conditions like InvestmentType = 'Bond' and State = 'TX'.\n",
    "\n",
    "Syntax Validation:\n",
    "Confirm that the generated query is syntactically correct according to SQL standards. It should be executable without syntax errors.\n",
    "Logical Accuracy:\n",
    "\n",
    "Ensure the logic of the query aligns with the task description. For instance, it should correctly aggregate the values as required by the task.\n",
    "\n",
    "Output should be only sql query and no explaination.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_gen_config': {'task_description': \"\\nExtract SQL Context:\\nReview the SQL context given in the input, including table definitions and any sample data inserted into these tables.\\n\\nFormulate Expected Query:\\nBased on the task description, determine the logical structure and components of the SQL query that should be generated. For instance, identify the relevant tables, columns, and conditions that should be included in the query.\\n\\nCheck Query Components:\\nEnsure the generated query includes the correct tables and columns specified in the SQL context.\\nVerify that the conditions and clauses in the query match the task description. For example, checking for conditions like InvestmentType = 'Bond' and State = 'TX'.\\n\\nSyntax Validation:\\nConfirm that the generated query is syntactically correct according to SQL standards. It should be executable without syntax errors.\\nLogical Accuracy:\\n\\nEnsure the logic of the query aligns with the task description. For instance, it should correctly aggregate the values as required by the task.\\n\\nOutput should be only sql query and no explaination.\\n\",\n",
       "  'no_samples': 0,\n",
       "  'seed_path': 'dager/backend/uploads/arshad/TextToSqlCheckSensitivityQATask/1721586825/texttosql_seed_data.json'},\n",
       " 'experiment_config': {'0': {'model_args': {'model_id': 'mistralai/Mistral-7B-v0.1',\n",
       "    'quantized': True},\n",
       "   'training_methods_args': {'r': 32,\n",
       "    'lora_alpha': 32,\n",
       "    'lora_dropout': 0.05,\n",
       "    'target_modules': ['q_proj', 'k_proj', 'v_proj']},\n",
       "   'training_args': {'fp16': True,\n",
       "    'num_train_epochs': 2,\n",
       "    'learning_rate': 0.0001,\n",
       "    'lr_scheduler_type': 'linear',\n",
       "    'warmup_ratio': 0.1}}},\n",
       " 'user_config': {'user_id': 'arshad',\n",
       "  'workflow_name': 'TextToSqlCheckSensitivityQATask',\n",
       "  'task_description': \"\\nExtract SQL Context:\\nReview the SQL context given in the input, including table definitions and any sample data inserted into these tables.\\n\\nFormulate Expected Query:\\nBased on the task description, determine the logical structure and components of the SQL query that should be generated. For instance, identify the relevant tables, columns, and conditions that should be included in the query.\\n\\nCheck Query Components:\\nEnsure the generated query includes the correct tables and columns specified in the SQL context.\\nVerify that the conditions and clauses in the query match the task description. For example, checking for conditions like InvestmentType = 'Bond' and State = 'TX'.\\n\\nSyntax Validation:\\nConfirm that the generated query is syntactically correct according to SQL standards. It should be executable without syntax errors.\\nLogical Accuracy:\\n\\nEnsure the logic of the query aligns with the task description. For instance, it should correctly aggregate the values as required by the task.\\n\\nOutput should be only sql query and no explaination.\\n\",\n",
       "  'budget': 2.0,\n",
       "  'seed_path': 'dager/backend/uploads/arshad/TextToSqlCheckSensitivityQATask/1721586825/texttosql_seed_data.json',\n",
       "  'session_id': 1721586826.07474,\n",
       "  'eval_config_path': 'eval_config.json'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_configs = client.initialize_workflow_configs(\n",
    "    evaluation_description= evaluation_policy,\n",
    "    workflow_name=\"TextToSqlCheckSensitivityQATask\",\n",
    "    seed_data_path=\"texttosql_seed_data.json\",\n",
    "    budget=2 # days\n",
    ") \n",
    "workflow_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ Once you're happy with hyper-parameters, you can submit the training workflow. It will **automatically execute experiments, evaluate them, and pick the best model** based your customized evaluation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_configs['experiment_config']['0']['training_args']['num_train_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      " Workflow running state: {'workflow_runnning_state_id': '1721586842'}\n"
     ]
    }
   ],
   "source": [
    "# Submit workflow for execution\n",
    "running_workflow_status = client.submit_workflow(\n",
    "    workflow_configs=workflow_configs\n",
    ")\n",
    "print(\" Workflow running state:\", running_workflow_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the status of all your workflows, by running the following command:\n",
    "\n",
    "- `runing_workflows`: shows the training workflows with `running` status.  \n",
    "- `finished_workflows`: shows executed workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Total finished workflows : 8\n",
      "Total running workflows : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user_id': 'arshad',\n",
       "  'workflow_runnning_state_id': '1721586842',\n",
       "  'workflow_name': 'TextToSqlCheckSensitivityQATask',\n",
       "  'workflow_start_timestamp': 1721586842.828452,\n",
       "  'status': 'running'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve user's workflows\n",
    "user_workflows = client.all_workflows()\n",
    "\n",
    "print( f\"Total finished workflows : {len(user_workflows['finished_workflows'])}\")\n",
    "print( f\"Total running workflows : {len(user_workflows['running_workflows'])}\")\n",
    "\n",
    "user_workflows['running_workflows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further details on the status of a specific workflow, you can run the following function:\n",
    "\n",
    "- `status`: overal status of workflow\n",
    "- `workflow_node_status`: status of all nodes\n",
    "- `workflow_name`: name of your workflow\n",
    "- `workflow_running_state_id`: id of your workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_id': 'arshad',\n",
       " 'workflow_runnning_state_id': '1721586842',\n",
       " 'workflow_name': 'TextToSqlCheckSensitivityQATask',\n",
       " 'workflow_start_timestamp': 1721586842.828452,\n",
       " 'status': True,\n",
       " 'workflow_node_status': {'DataGenConfig-172158684276520kyab': 'Executed',\n",
       "  'DataPrepConfig-172158684276524frjf': 'Executed',\n",
       "  'SFTrainingConfig-172158684276533sjlf': 'Executed',\n",
       "  'EvalResponseGenConfig-172158684276536gikb': 'Executed',\n",
       "  'EvalConfig-172158684276545vwmm': 'Executed',\n",
       "  'PickBestConfig-172158684276526yrmk': 'Executed'},\n",
       " 'workflow_completed_timestamp': 1721590603.874977}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check status of the running workflow\n",
    "workflow_status = client.get_workflow_status('1721586842')\n",
    "workflow_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'cluster_name': 'DeploymentState-1721599750.281206', 'status': 'Deployment started'}\n"
     ]
    }
   ],
   "source": [
    "# Deploy the workflow\n",
    "workflow_id = '1721586842'\n",
    "deployment_status = client.deploy_workflow(\n",
    "    workflow_id\n",
    ")\n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'DeploymentState-1721599750.281206',\n",
       " 'ip': '3.80.255.142',\n",
       " 'gradio-playground': 'http://3.80.255.142:8000',\n",
       " 'api-access': 'http://3.80.255.142:9000',\n",
       " 'status': 'Deployed'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_details = client.get_workflow_deployment_status('DeploymentState-1721599750.281206')\n",
    "deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model id\n",
    "import requests\n",
    "model_details = requests.get( f\"http://3.80.255.142:9000/v1/models\").json()\n",
    "model_id = model_details['data'][0]['id']\n",
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt :\n",
      " ## sql context :\n",
      "CREATE TABLE Funding (company_id INT, funding_year INT, amount INT); INSERT INTO Funding (company_id, funding_year, amount) VALUES (1, 2015, 3000000); INSERT INTO Funding (company_id, funding_year, amount) VALUES (2, 2017, 5000000); INSERT INTO Funding (company_id, funding_year, amount) VALUES (3, 2017, 7000000);\n",
      "\n",
      "## Query generation task:\n",
      "What is the total funding received by companies founded in 2017, ordered by the amount of funding?\n",
      "\n",
      " \n",
      "LLM Response:\n",
      "## Query:\n",
      "SELECT company_id, SUM(amount) as total_funding FROM Funding WHERE funding_year = 2017 GROUP BY company_id ORDER BY total_funding DESC;\n",
      "\n",
      "Original Response:\n",
      " SELECT company_id, SUM(amount) as total_funding FROM Funding WHERE funding_year = 2017 GROUP BY company_id ORDER BY total_funding DESC;\n",
      "-----\n",
      "\n",
      "\n",
      "Prompt :\n",
      " ## sql context :\n",
      "CREATE TABLE GraduateStudents (StudentID INT, Name VARCHAR(50), Department VARCHAR(50), Publications INT, PublicationYear INT);\n",
      "\n",
      "## Query generation task:\n",
      "How many publications were made by graduate students in the Mathematics department in the year 2020?\n",
      "\n",
      " \n",
      "LLM Response:\n",
      "## Query:\n",
      "SELECT COUNT(*) FROM GraduateStudents WHERE Department = 'Mathematics' AND PublicationYear = 2020;\n",
      "\n",
      "Original Response:\n",
      " SELECT COUNT(Publications) FROM GraduateStudents WHERE Department = 'Mathematics' AND PublicationYear = 2020;\n",
      "-----\n",
      "\n",
      "\n",
      "Prompt :\n",
      " ## sql context :\n",
      "CREATE TABLE spacecraft (id INT, name VARCHAR(100), agency VARCHAR(50), launch_date DATE); INSERT INTO spacecraft (id, name, agency, launch_date) VALUES (1, 'Voyager 1', 'NASA', '1977-09-05'); INSERT INTO spacecraft (id, name, agency, launch_date) VALUES (2, 'Galileo', 'NASA', '1989-10-18'); INSERT INTO spacecraft (id, name, agency, launch_date) VALUES (3, 'Cassini', 'CNES', '1997-10-15'); INSERT INTO spacecraft (id, name, agency, launch_date) VALUES (4, 'Mars Express', 'ESA', '2003-06-02');\n",
      "\n",
      "## Query generation task:\n",
      "Which space agencies have launched spacecraft before 2000?\n",
      "\n",
      " \n",
      "LLM Response:\n",
      "## Query:\n",
      "SELECT DISTINCT agency FROM spacecraft WHERE launch_date < '2000-01-01';\n",
      "\n",
      "Original Response:\n",
      " SELECT DISTINCT agency FROM spacecraft WHERE YEAR(launch_date) < 2000;\n",
      "-----\n",
      "\n",
      "\n",
      "Prompt :\n",
      " ## sql context :\n",
      "CREATE TABLE climate_finance (year INT, donor VARCHAR(20), recipient VARCHAR(20), category VARCHAR(10), amount FLOAT); INSERT INTO climate_finance (year, donor, recipient, category, amount) VALUES (2020, 'USA', 'India', 'mitigation', 10000000), (2020, 'USA', 'Brazil', 'adaptation', 15000000), (2020, 'Germany', 'Indonesia', 'mitigation', 8000000), (2020, 'France', 'South Africa', 'adaptation', 12000000);\n",
      "\n",
      "## Query generation task:\n",
      "What's the total amount of climate finance committed by developed countries to developing countries for mitigation and adaptation projects in 2020?\n",
      "\n",
      " \n",
      "LLM Response:\n",
      "## Query:\n",
      "SELECT SUM(amount) FROM climate_finance WHERE year = 2020 AND (donor IN ('USA', 'Germany', 'France') AND recipient IN ('India', 'Brazil', 'Indonesia', 'South Africa') AND category IN ('mitigation', 'adaptation'));\n",
      "\n",
      "Original Response:\n",
      " SELECT SUM(amount) FROM climate_finance WHERE year = 2020 AND (donor IN ('USA', 'Germany', 'France') AND recipient IN ('India', 'Brazil', 'Indonesia', 'South Africa') AND category IN ('mitigation', 'adaptation'));\n",
      "-----\n",
      "\n",
      "\n",
      "Prompt :\n",
      " ## sql context :\n",
      "CREATE TABLE ClientInvestments (ClientID INT, InvestmentType VARCHAR(20), Value FLOAT); INSERT INTO ClientInvestments (ClientID, InvestmentType, Value) VALUES (1, 'Stock', 10000), (1, 'Bond', 20000), (2, 'Stock', 30000), (2, 'Bond', 15000), (3, 'Stock', 5000), (3, 'Bond', 25000), (4, 'Stock', 40000), (4, 'Bond', 30000), (5, 'Stock', 7000), (5, 'Bond', 18000); CREATE TABLE Clients (ClientID INT, State VARCHAR(20)); INSERT INTO Clients (ClientID, State) VALUES (1, 'NY'), (2, 'TX'), (3, 'CA'), (4, 'NY'), (5, 'TX');\n",
      "\n",
      "## Query generation task:\n",
      "What is the total value of investments in bonds for clients residing in Texas?\n",
      "\n",
      " \n",
      "LLM Response:\n",
      "## Query:\n",
      "SELECT SUM(Value) FROM ClientInvestments CI JOIN Clients C ON CI.ClientID = C.ClientID WHERE C.State = 'TX' AND InvestmentType = 'Bond';\n",
      "\n",
      "Original Response:\n",
      " SELECT SUM(Value) FROM ClientInvestments CI JOIN Clients C ON CI.ClientID = C.ClientID WHERE C.State = 'TX' AND InvestmentType = 'Bond';\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "import json\n",
    "sql_data = json.load(open('texttosql_seed_data.json'))\n",
    "\n",
    "url = \"http://3.80.255.142:9000/v1/completions\"\n",
    "\n",
    "for d in sql_data[-5:]:\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"prompt\": [d['query']],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    print(\"Prompt :\\n\", d['query'], \"\\nLLM Response:\")\n",
    "    print(response.json()['choices'][0]['text'])\n",
    "    print(\"\\nOriginal Response:\\n\", d['response'])\n",
    "    print(\"-----\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'DeploymentState-1721599750.281206',\n",
       " 'status': 'Deployment Killed'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.kill_deployment(\n",
    "    'DeploymentState-1721599750.281206'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2_p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
