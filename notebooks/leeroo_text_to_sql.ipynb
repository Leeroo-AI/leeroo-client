{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize LLM for Text to SQL Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will find the best customized model on the text-to-sql application by running multiple training experiment, and picking the best model based on a customized evaluation system. Finally, you can easily deploy the customized model.\n",
    "\n",
    "We utilize [Synthetic Text2SQL ðŸ¤—](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql). This dataset contains pairs of natural language descriptions and corresponding SQL queries. The dataset will be used to train our model. Additionally, we will provide the model with SQL context to ensure accurate and context-aware query generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install leeroo-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or install it from source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Leeroo-AI/leeroo-client\n",
    "%cd leeroo-client \n",
    "!pip install -e .\n",
    "%cd ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leeroo dager supports the following format for training dataset:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"query\": QUERY,\n",
    "        \"response\": RESPONSE,\n",
    "    },\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from leeroo_client.client import LeerooClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = datasets.load_dataset(\"gretelai/synthetic_text_to_sql\")\n",
    "n_seed_samples = 1000\n",
    "data = []\n",
    "\n",
    "for d in tqdm(dataset['train']):\n",
    "    data.append(\n",
    "        dict(\n",
    "            query = f\"## sql context :\\n{d['sql_context']}\\n\\n## Query generation task:\\n{d['sql_prompt']}\\n\\n\",\n",
    "            response = d['sql']\n",
    "        )\n",
    "    )\n",
    "    if len(data) == n_seed_samples:\n",
    "        break\n",
    "\n",
    "json.dump(data, open('texttosql_seed_data.json', 'w'))\n",
    "print(len(data))\n",
    "pprint(data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your API key in [here](http://app.leeroo.com/dashboard), if you don't have one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leeroo_api_key = #LEEROO_API_KEY\n",
    "client = LeerooClient(\n",
    "    leeroo_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For designing the workflow of experiments, please provide:\n",
    "\n",
    "- `evaluation_criteria` (optional): A short description of what are important factors in your mind for scoring the responses of LLM. Just describe them in natural language.\n",
    "- `workflow_name` : The name of this experiment. This will be later saved along with the id of workflow.  \n",
    "- `seed_data_path`: The dataset should follow JSON format with `query` and `response` as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_criteria = \\\n",
    "\"\"\"\n",
    "Extract SQL Context:\n",
    "Review the SQL context given in the input, including table definitions and any sample data inserted into these tables.\n",
    "\n",
    "Formulate Expected Query:\n",
    "Based on the task description, determine the logical structure and components of the SQL query that should be generated. For instance, identify the relevant tables, columns, and conditions that should be included in the query.\n",
    "\n",
    "Check Query Components:\n",
    "Ensure the generated query includes the correct tables and columns specified in the SQL context.\n",
    "Verify that the conditions and clauses in the query match the task description. For example, checking for conditions like InvestmentType = 'Bond' and State = 'TX'.\n",
    "\n",
    "Syntax Validation:\n",
    "Confirm that the generated query is syntactically correct according to SQL standards. It should be executable without syntax errors.\n",
    "Logical Accuracy:\n",
    "\n",
    "Ensure the logic of the query aligns with the task description. For instance, it should correctly aggregate the values as required by the task.\n",
    "\n",
    "Output should be only sql query and no explaination.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_configs = client.initialize_workflow_configs(\n",
    "    evaluation_criteria=evaluation_criteria,\n",
    "    workflow_name=\"TextToSqlCheckSensitivityQATask\",\n",
    "    seed_data_path=\"texttosql_seed_data.json\",\n",
    "    budget=2 # each experiment needs at least 2 unites of time, you can increase it for running more experiments\n",
    ") \n",
    "workflow_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ Once you're happy with hyper-parameters, you can submit the training workflow. It will **automatically execute experiments, evaluate them, and pick the best model** based your customized evaluation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_configs['experiment_config']['0']['training_args']['num_train_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit workflow for execution\n",
    "running_workflow_status = client.submit_workflow(\n",
    "    workflow_configs=workflow_configs\n",
    ")\n",
    "print(\" Workflow running state:\", running_workflow_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the status of all your workflows, by running the following command:\n",
    "\n",
    "- `runing_workflows`: shows the training workflows with `running` status.  \n",
    "- `finished_workflows`: shows executed workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve user's workflows\n",
    "user_workflows = client.all_workflows()\n",
    "\n",
    "print( f\"Total finished workflows : {len(user_workflows['finished_workflows'])}\")\n",
    "print( f\"Total running workflows : {len(user_workflows['running_workflows'])}\")\n",
    "\n",
    "user_workflows['running_workflows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further details on the status of a specific workflow, you can run the following function:\n",
    "\n",
    "- `status`: overal status of workflow\n",
    "- `workflow_node_status`: status of all nodes\n",
    "- `workflow_name`: name of your workflow\n",
    "- `workflow_running_state_id`: id of your workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of the running workflow\n",
    "workflow_status = client.get_workflow_status('1721586842')\n",
    "workflow_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the workflow is executed, you can deploy it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the workflow\n",
    "workflow_id = '1721586842'\n",
    "deployment_status = client.deploy_workflow(\n",
    "    workflow_id\n",
    ")\n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the status of deployment by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = client.get_workflow_deployment_status('DeploymentState-1721599750.281206')\n",
    "deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model id\n",
    "import requests\n",
    "model_details = requests.get( f\"http://3.80.255.142:9000/v1/models\").json()\n",
    "model_id = model_details['data'][0]['id']\n",
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "import json\n",
    "sql_data = json.load(open('texttosql_seed_data.json'))\n",
    "\n",
    "url = \"http://3.80.255.142:9000/v1/completions\"\n",
    "\n",
    "for d in sql_data[-5:]:\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"prompt\": [d['query']],\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    print(\"Prompt :\\n\", d['query'], \"\\nLLM Response:\")\n",
    "    print(response.json()['choices'][0]['text'])\n",
    "    print(\"\\nOriginal Response:\\n\", d['response'])\n",
    "    print(\"-----\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kill the deployed model by running the following command: (you can later deploy it again, if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.kill_deployment(\n",
    "    'DeploymentState-1721599750.281206'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2_p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
