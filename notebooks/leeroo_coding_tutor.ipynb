{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize LLM for Coding Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will find the best customized model on the coding domain by running multiple training experiment, and picking the best model based on a customized evaluation system. Finally, you can easily deploy the customized model.\n",
    "\n",
    "We utilize [CodeAlpaca 20K ðŸ¤—](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k). CodeAlpaca is a generic instruction-following dataset for the coding application, which is based on Stanford Alpaca. Further details are available [here](https://github.com/sahil280114/codealpaca)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install leeroo-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or install it from source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Leeroo-AI/leeroo-client\n",
    "%cd leeroo-client \n",
    "!pip install -e .\n",
    "%cd ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leeroo dager supports the following format for training dataset:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"query\": QUERY,\n",
    "        \"response\": RESPONSE,\n",
    "    },\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare seed examples in required format\n",
    "import json\n",
    "import datasets\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from leeroo_client.client import LeerooClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"sahil2801/CodeAlpaca-20k\")['train']\n",
    "## modify the number of training samples here\n",
    "n_seed_samples = 1000\n",
    "data = []\n",
    "for d in tqdm(dataset):\n",
    "    data.append({'query':d['instruction']+\"\\n\"+d['input'],'response':d['output']})\n",
    "    if len(data) == n_seed_samples:\n",
    "        break\n",
    "\n",
    "json.dump(data, open('coding_tutor.json', 'w'))\n",
    "print(len(data))\n",
    "pprint(data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your API key in [here](http://app.leeroo.com/dashboard), if you don't have one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leeroo_api_key = #LEEROO_API_KEY\n",
    "client = LeerooClient(\n",
    "    leeroo_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For designing the workflow of experiments, please provide:\n",
    "\n",
    "- `evaluation_description` (optional): A short description of what are important factors in your mind for scoring the responses of LLM. Just describe them in natural language.\n",
    "- `workflow_name` : The name of this experiment. This will be later saved along with the id of workflow.  \n",
    "- `seed_data_path`: The dataset should follow JSON format with `query` and `response` as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_description = \\\n",
    "\"\"\"\n",
    "- Assess clarity by determining if the code and explanations are well-structured and easy to understand.\n",
    "- Evaluate accuracy by verifying the correctness of the code and whether it performs the intended task without errors.\n",
    "- Check completeness by ensuring that the response addresses all parts of the prompt and includes necessary details.\n",
    "- Finally, judge usability by considering if the code is efficient, follows best practices, and includes comments or \n",
    "documentation where appropriate.\n",
    "\n",
    "Each response should be rated on these aspects to ensure a comprehensive evaluation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_configs = client.initialize_workflow_configs(\n",
    "    evaluation_description= evaluation_description,\n",
    "    workflow_name=\"leeroo_coding_tutor\",\n",
    "    seed_data_path=\"coding_tutor.json\",\n",
    "    budget=2 # each experiment needs at least 2 unites of time, you can increase it for running more experiments\n",
    ") \n",
    "\n",
    "workflow_configs\n",
    "# currently data generation module is turned off. We will have it in few weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can edit the hyper-parameters of suggested configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow_configs['experiment_config']['0']['training_args']['num_train_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ Once you're happy with hyper-parameters, you can submit the training workflow. It will **automatically execute experiments, evaluate them, and pick the best model** based your customized evaluation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      " Workflow running state: {'workflow_runnning_state_id': '1722846755'}\n"
     ]
    }
   ],
   "source": [
    "# Submit workflow for execution\n",
    "running_workflow_status = client.submit_workflow(\n",
    "    workflow_configs=workflow_configs\n",
    ")\n",
    "print(\" Workflow running state:\", running_workflow_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the status of all your workflows, by running the following command:\n",
    "\n",
    "- `runing_workflows`: shows the training workflows with `running` status.  \n",
    "- `finished_workflows`: shows executed workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve user's workflows\n",
    "user_workflows = client.all_workflows()\n",
    "\n",
    "print( f\"Total finished workflows : {len(user_workflows['finished_workflows'])}\")\n",
    "print( f\"Total running workflows : {len(user_workflows['running_workflows'])}\")\n",
    "\n",
    "user_workflows['running_workflows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further details on the status of a specific workflow, you can run the following function:\n",
    "\n",
    "- `status`: overal status of workflow\n",
    "- `workflow_node_status`: status of all nodes\n",
    "- `workflow_name`: name of your workflow\n",
    "- `workflow_running_state_id`: id of your workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of the running workflow\n",
    "workflow_status = client.get_workflow_status('1722846755')\n",
    "workflow_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.print_workflow(workflow_runnning_state_id='1722846755'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the workflow is executed, you can deploy it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy the workflow\n",
    "workflow_id = '1722764222' \n",
    "deployment_status = client.deploy_workflow(\n",
    "    workflow_id\n",
    ")\n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the status of deployment by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_workflow_deployment_status('DeploymentState-1722772956.964921')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model id\n",
    "import requests\n",
    "model_id = requests.get( \"http://54.227.170.247:9000/v1/models\").json()['data'][0]['id']\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "url = \"http://54.227.170.247:9000/v1/chat/completions\"\n",
    "data = {\n",
    "    \"model\": model_id,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Create an array of length 5 which contains all even numbers between 1 and 10.\"}],\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.9\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json()['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kill the deployed model by running the following command: (you can later deploy it again, if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.kill_deployment(\n",
    "    'DeploymentState-1722772956.964921'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2_p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
